


    {.emit: ["""
    for (size_t in = 0; in < """, layer.numInputs, """; ++in)
        {
            auto& in_neurons_gradient_in = """, layerBackpropInfo.inputGradient, """.p->data[in];
#pragma omp simd reduction(+ : in_neurons_gradient_in)
            for (size_t out = 0; out < """, layer.numOutputs, """; ++out)
            {
                const size_t i = out + """, layer.numOutputs, """ * in;
                //weightsIndex(in, out, num_in_neurons, num_out_neurons);
                """, layerBackpropInfo.paramGradient.weights, """.p->data[i] +=
                    """, inPostActivation, """[in] * """, layerBackpropInfo.paramGradient.bias, """.p->data[out];
                in_neurons_gradient_in +=
                    """, layer.weights, """.p->data[i] * """, layerBackpropInfo.paramGradient.bias ,""".p->data[out];
            }
        }
    """].}




    # {.emit: ["""
    # auto& num_in_neurons = """, layer.numInputs, """;
    # auto& num_out_neurons = """, layer.numOutputs, """;
    # auto& out_neurons_activation = """, result, """.p->data;
    # auto& weights = """, layer.weights, """.p->data;
    # auto& in_neurons_activation = """, input, """;
    # for (size_t in = 0; in < num_in_neurons; ++in)
    # {
    #     for (size_t out = 0; out < num_out_neurons; ++out)
    #     {
    #         const size_t i = out + num_out_neurons * num_in_neurons; // TODO use weightsIndex
    #         out_neurons_activation[out] += weights[i] * in_neurons_activation[in];
    #     }
    # }
    # """].}